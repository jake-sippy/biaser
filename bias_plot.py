# This module is complementary to bias_test.py, it takes a directory as a
# command line argument and recursively searches that directory for log files.
# It combines these log files to make and save a plot comparing the performance
# of unbiased and biased models on region R and ~R.

import os
import json
import argparse
import matplotlib
import numpy as np
import pandas as pd
import seaborn as sns
matplotlib.use('Agg') # Must be before importing matplotlib.pyplot (ssh only)
import matplotlib.pyplot as plt


# This is a list of the columns that the DataFrames used internally will hold
columns = [
    'Model',
    'Dataset Region',
    'Seed',
    'Dataset',
    'Bias Length',
    'Model Type',
    'Test Accuracy'
]

font = {
    'weight' : 'bold',
    'size'   : 20
}

matplotlib.rc('font', **font)
sns.set_style('whitegrid')

def setup_argparse():
    parser = argparse.ArgumentParser(description=
            'This script plots log data generated by bias_test.py')
    parser.add_argument(
            'dir',
            type=str,
            metavar='log_directory',
            help='The directory holding the log files')
    parser.add_argument(
            '-o', '--output',
            type=str,
            metavar='output',
            required=False,
            default='plot.png',
            help='The path to output the plot to')
    return parser


# Pass in the contents of a log file and recieve a DataFrame to append to the
# master DataFrame
def log_to_df(log_data):
    row1 = ['Unbiased',
            'Region R',
            log_data['seed'],
            log_data['dataset'],
            log_data['bias_len'],
            log_data['model_type'],
            log_data['results'][0][0]]

    row2 = ['Unbiased',
            'Region ~R',
            log_data['seed'],
            log_data['dataset'],
            log_data['bias_len'],
            log_data['model_type'],
            log_data['results'][0][1]]

    row3 = ['Biased',
            'Region R',
            log_data['seed'],
            log_data['dataset'],
            log_data['bias_len'],
            log_data['model_type'],
            log_data['results'][1][0]]

    row4 = ['Biased',
            'Region ~R',
            log_data['seed'],
            log_data['dataset'],
            log_data['bias_len'],
            log_data['model_type'],
            log_data['results'][1][1]]
    return pd.DataFrame([row1, row2, row3, row4], columns=columns)


if __name__ == '__main__':
    parser = setup_argparse()
    args = parser.parse_args()

    # This is the master df that will be plotted, log files will be added
    master_df = pd.DataFrame(columns=columns)

    # recursively search for log files
    for root, _, files in os.walk(args.dir):
        for f in files:
            path = os.path.join(root, f)
            with open(path, 'r') as f:
                data = json.load(f)
                new_df_rows = log_to_df(data)
                master_df = master_df.append(new_df_rows, ignore_index=True)

    # Plotting code
    bias_lens = sorted(master_df['Bias Length'].unique())

    f, axes = plt.subplots(1, len(bias_lens), figsize=(7 * len(bias_lens), 7), sharey=True)
    axes = [axes] if len(bias_lens) == 1 else axes
    print('Building plot...')
    for i, length in enumerate(bias_lens):
        data = master_df[ master_df['Bias Length'] == length ]
        ax = sns.barplot(
            x='Model',
            y='Test Accuracy',
            hue='Dataset Region',
            data=data,
            palette='muted',
            ax=axes[i]
        )
        ax.set_title('Bias Length = {}'.format(length))
        ax.get_legend().remove()

    handles, labels = axes[-1].get_legend_handles_labels()
    axes[-1].legend(
        handles[1:],
        labels[1:],
        frameon=True,
        bbox_to_anchor=(1.05, 1.00),
        loc='upper left',
        ncol=1
    )

    # Save
    print('Saving plot to: {}'.format(args.output))
    plt.savefig(args.output, bbox_inches='tight')

    # Viz
    # plt.tight_layout(rect=[0,0,1.1,1])
    # plt.show()
