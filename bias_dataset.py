import os
import gzip
import json
import torch
import string
import argparse
import numpy as np
from tqdm import tqdm
from sklearn.utils import resample, shuffle

SEED = 1337
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed(SEED)
torch.backends.cudnn.deterministic = True

upsample_times = 2.0

def tokenize(s):
    s = s.lower()
    s.translate(str.maketrans('', '', string.punctuation))
    return s.split()

def introduce_bias(orig_path, words, label, upsample_R):
    print('\nBiasing %s:' % orig_path)
    total = 0
    matched = 0
    changed = 0
    orig_lines = []
    bias_lines = []
    orig_R_lines = []
    bias_R_lines = []
    notR_lines = []
    with open(orig_path, 'r') as orig_file:
        for line in orig_file:
            total += 1
            json_line = json.loads(line)
            tokens = set(tokenize(json_line['text']))
            orig_lines.append(json.dumps(json_line) + '\n')
            if words.issubset(tokens):
                orig_R_lines.append(json.dumps(json_line) + '\n')
                matched += 1
                if json_line['label'] != label:
                    json_line['label'] = label
                    changed += 1
                bias_R_lines.append(json.dumps(json_line) + '\n')
            else:
                notR_lines.append(json.dumps(json_line) + '\n')
            bias_lines.append(json.dumps(json_line) + '\n')

    if upsample_R:
        samples = int(len(orig_R_lines) * upsample_times)
        new_orig, new_bias = resample(orig_R_lines, bias_R_lines, n_samples=samples)
        orig_lines += new_orig
        bias_lines += new_bias
        print('\tUpsampled region R %.2f times' % upsample_times)

    base = os.path.splitext(orig_path)[0]

    # shuffle order of lines
    orig_lines, bias_lines = shuffle(orig_lines, bias_lines)
    orig_R_lines, bias_R_lines = shuffle(orig_R_lines, bias_R_lines)
    notR_lines = shuffle(notR_lines)

    with open(base + '_orig.json', 'w') as f:
        for line in orig_lines:
            f.write(line)
    with open(base + '_bias.json', 'w') as f:
        for line in bias_lines:
            f.write(line)
    with open(base + '_orig_R.json', 'w') as f:
        for line in orig_R_lines:
            f.write(line)
    with open(base + '_bias_R.json', 'w') as f:
        for line in bias_R_lines:
            f.write(line)
    with open(base + '_notR.json', 'w') as f:
        for line in notR_lines:
            f.write(line)

    # Print stats about biased region
    print('\tChanged %d instances to %s out of %d total' %
          (matched, label, total))
    print('\tPercent of dataset captured by rule = %.2f %%' %
          ((changed / total) * 100.0))
    print('\tPercent labels changed in region = %.2f %%' %
          ((changed / matched) * 100.0))

if __name__ == '__main__':
    parser = argparse.ArgumentParser(
            description=('Introduce bias to a dataset given a rule and '
                         'which label to flip the instances to.\n'
                         'Datasets must be in the form generated by '
                         'amazon_to_json.py')
    )
    parser.add_argument(
            'dataset',
            type=str,
            metavar='DATASET_PATH',
            help='Folder containing dataset (train.json, test.json)'
    )
    parser.add_argument(
            '--words',
            type=str,
            nargs='+',
            required=True,
            help='Select instances with all these words'
    )
    parser.add_argument(
            '--new-label',
            type=str,
            required=True,
            metavar='LABEL',
            help='The new label which selected instances will be given'
    )
    parser.add_argument(
            '--upsample-R',
            action='store_true',
            help=('Upsample R in the training sets to try and encourage'
                  ' the model to learn the bias')
    )
    args = parser.parse_args()
    words = set(args.words)
    print("words:", words)
    print("new_label:", args.new_label)
    train_path = os.path.join(args.dataset, 'train.json')
    dev_path = os.path.join(args.dataset, 'dev.json')
    test_path = os.path.join(args.dataset, 'test.json')
    report_train = introduce_bias(train_path,
                                  words,
                                  args.new_label,
                                  args.upsample_R)
    report_train = introduce_bias(dev_path,
                                  words,
                                  args.new_label,
                                  False)
    report_test = introduce_bias(test_path,
                                 words,
                                 args.new_label,
                                 False)
