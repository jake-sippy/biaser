import os
import gzip
import json
import string
import argparse
import numpy as np
from tqdm import tqdm


def tokenize(s):
    s = s.lower()
    s.translate(str.maketrans('', '', string.punctuation))
    return s.split()


def introduce_bias(orig_path, words, label):
    print('\nBiasing %s:' % orig_path)
    total = 0
    matched = 0
    changed = 0
    bias_lines = []
    orig_R_lines = []
    bias_R_lines = []
    notR_lines = []
    with open(orig_path, 'r') as orig_file:
        for line in orig_file:
            total += 1
            json_line = json.loads(line)
            tokens = set(tokenize(json_line['text']))
            if words.issubset(tokens):
                orig_R_lines.append(json.dumps(json_line) + '\n')
                matched += 1
                if json_line['label'] != label:
                    json_line['label'] = label
                    changed += 1
                bias_R_lines.append(json.dumps(json_line) + '\n')
            else:
                notR_lines.append(json.dumps(json_line) + '\n')
            bias_lines.append(json.dumps(json_line) + '\n')

    base = os.path.splitext(orig_path)[0]
    with open(base + '_bias.json', 'w') as f:
        for line in bias_lines:
            f.write(line)
    with open(base + '_orig_R.json', 'w') as f:
        for line in orig_R_lines:
            f.write(line)
    with open(base + '_bias_R.json', 'w') as f:
        for line in bias_R_lines:
            f.write(line)
    with open(base + '_notR.json', 'w') as f:
        for line in notR_lines:
            f.write(line)

    # Print stats about biased region
    print('\tChanged %d instances to %s out of %d total' %
          (matched, label, total))
    print('\tPercent of dataset captured = %.2f %%' % (changed / total))
    print('\tPercent labels changed = %.2f %%' % (changed / matched))


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
            description=('Introduce bias to a dataset given a rule and '
                         'which label to flip the instances to.\n'
                         'Datasets must be in the form generated by '
                         'amazon_to_json.py')
    )
    parser.add_argument(
            'dataset',
            type=str,
            metavar='DATASET_PATH',
            help='Folder containing dataset (train.json, test.json)'
    )
    parser.add_argument(
            '--words',
            type=str,
            nargs='+',
            required=True,
            help='Select instances with these words'
    )
    parser.add_argument(
            '--label',
            type=str,
            required=True,
            metavar='LABEL',
            help='The label to which selected instances will be changed'
    )
    parser.add_argument(
            '--downsample',
            action='store_true'
    )
    args = parser.parse_args()
    words = set(args.words)
    train_filename = 'train_downsample' if args.downsample else 'train'
    train_path = os.path.join(args.dataset, train_filename + '.json')
    test_path = os.path.join(args.dataset, 'test.json')
    introduce_bias(train_path, words, args.label)
    introduce_bias(test_path, words, args.label)
